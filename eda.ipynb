{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a707003d",
   "metadata": {},
   "source": [
    "# AIAP Foundation Self Practice\n",
    "\n",
    "The objective is to predict the students' O-level mathematics examination score to help the school to identify weaker students prior to the examination using the dataset provided. In your submission, you should evaluate at least 3 suitable models for estimating the students' scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e14132e",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "| Column               | Description                        |\n",
    "| -------------------- | ---------------------------------- |\n",
    "| student_id           | Unique ID for each student         |\n",
    "| number_of_siblings   | Number of siblings                 |\n",
    "| direct_admission     | Mode of entering the school        |\n",
    "| CCA                  | Enrolled CCA                       |\n",
    "| learning_style       | Primary learning style             |\n",
    "| tuition              | Indication of whether the student has a tuition   |\n",
    "| final_test           | Student's O-level mathematics examination score   |\n",
    "| n_male               | Number of male classmates          |\n",
    "| n_female             | Number of female classmates        |\n",
    "| gender               | Gender type                        |\n",
    "| age                  | Age of the student                 |\n",
    "| hours_per_week       | Number of hours student studies per week          |\n",
    "| attendance_rate      | Attendance rate of the student (%) |\n",
    "| sleep_time           | Daily sleeping time (hour:minutes) |\n",
    "| wake_time            | Daily waking up time (hour:minutes)               |\n",
    "| mode_of_transport    | Mode of transport to school        |\n",
    "| bag_color            | Colours of student's bag           |\n",
    "\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f1bc5b",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d812d",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9755958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sys\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "# Load third party libraries\n",
    "from app_logging.app_logging import Logger\n",
    "Logger.initialize()\n",
    "Logger.debug('Loaded libraries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8eb799",
   "metadata": {},
   "source": [
    "### Setting notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ad09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Jupyter notebook settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 999)\n",
    "\n",
    "Logger.debug('Starting EDA.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd26d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting global variables for dataset path and path to save plots and graphs\n",
    "FILE_PATH = \"./data/regression_bonus_practice_data.csv\"\n",
    "PLOT_PATH = \"./images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee10c27",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c99560",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(f\"Attempting to read the file at: {FILE_PATH}\")\n",
    "    # The main attempt to read the CSV file\n",
    "    df = pd.read_csv(FILE_PATH)    \n",
    "    print(\"\\n✅ File read successfully!\")\n",
    "    print(\"Here are the first 5 rows:\")\n",
    "    print(f\"Dataset read has {df.shape[0]:,} rows by {df.shape[1]:,} columns.\")\n",
    "    print(df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n❌ ERROR: The file at '{FILE_PATH}' was not found.\")\n",
    "    print(\"Please make sure the file exists and the path is correct.\")\n",
    "    sys.exit(1) # Stop the program with an error code\n",
    "\n",
    "except pd.errors.ParserError:\n",
    "    print(f\"\\n❌ ERROR: The file at '{FILE_PATH}' is not a valid CSV.\")\n",
    "    print(\"Please check that the file is a standard, comma-separated text file.\")\n",
    "    sys.exit(1) # Stop the program with an error code\n",
    "    \n",
    "except Exception as e:\n",
    "    # Catch any other unexpected errors\n",
    "    print(f\"\\n❌ An unexpected error occurred: {e}\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d0839bb",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Load the dataset: first check the file exists and stop execution with a clear message if not.\n",
    "file_path_obj = Path(FILE_PATH)\n",
    "Logger.debug(f'Loading dataset from {FILE_PATH}.')\n",
    "if not file_path_obj.is_file():\n",
    "    Logger.error(f'File not found at {FILE_PATH}')\n",
    "    print(f\"File not found at: {FILE_PATH}\")\n",
    "    # print(\"Please check the FILE_PATH variable or place the CSV at the expected location.\")\n",
    "    print(\"Exiting program.\")\n",
    "    sys.exit(1)\n",
    "# If the file exists, read it into a DataFrame and show the dataset's dimensions.\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "print(f\"Dataset loaded: {df.shape[0]:,} rows by {df.shape[1]:,} columns.\")\n",
    "Logger.debug(f'Loaded dataset of {df.shape[0]:,} rows by {df.shape[1]:,} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735e8f2d",
   "metadata": {},
   "source": [
    "### Checking dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the dataset structure and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35e7bff",
   "metadata": {},
   "source": [
    "### Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c65dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with missing data\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_percent = df.isnull().mean() * 100\n",
    "\n",
    "if missing_counts.sum() > 0:\n",
    "    # When there are missing values\n",
    "\n",
    "    # Filter columns with missing values\n",
    "    missing_columns = missing_counts[missing_counts > 0].index.tolist()\n",
    "    Logger.debug(f'Columns with missing values: {missing_columns}')\n",
    "\n",
    "    # Display columns with missing values, their count, and percentage\n",
    "    print(\"Columns with missing data:\\n\")\n",
    "    for col in missing_columns:\n",
    "        print(f\"{col:<25} : {missing_counts[col]:>6,} missing ({missing_percent[col]:>5.2f}%)\")\n",
    "        Logger.debug(f\"{col:<25} : {missing_counts[col]:>6,} missing ({missing_percent[col]:>5.2f}%)\")\n",
    "else:\n",
    "    # When there are no missing values\n",
    "    Logger.info('There are no missing values in the dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db506330",
   "metadata": {},
   "source": [
    "### Checking numerical columns statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef13060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying transposed output of numerical columns statistics\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea95d8",
   "metadata": {},
   "source": [
    "### Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0446f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates\n",
    "if df.duplicated().sum() == 0:\n",
    "    # When there are no duplicatres in the dataset\n",
    "    # print('There are no duplicates in the dataset.')\n",
    "    Logger.info('There are no duplicates in the dataset.')\n",
    "else:\n",
    "    # When there are duplicates found in the dataset\n",
    "    print('There are duplicates found in the dataset.')\n",
    "    print(f\"There are a total of {len(df.duplcated().sum):,} duplicates.\")\n",
    "    print('Recommend dropping the duplicates.')\n",
    "    Logger.debug(f'There are {len(df.duplcated().sum):,} duplicate records found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706d2524",
   "metadata": {},
   "source": [
    "### Checking non-numerical columns statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac86b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking object type columns\n",
    "# df.select_dtypes(include = 'object').value_counts()\n",
    "Logger.info('Listing non-numerical columns statistics.')\n",
    "value_counts_dict = {col: df[col].value_counts() for col in df.select_dtypes(include='object').columns}\n",
    "\n",
    "print('Breakdown of the frequency of values in the object data type.')\n",
    "print('-' * 60)\n",
    "pprint.pprint(value_counts_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567271f4",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b706a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logger.debug('Starting the data cleaning phase.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d000aa1",
   "metadata": {},
   "source": [
    "### Cleaning `CCA` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0939575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the breakdown of the CCA activities students have joined\n",
    "display(df['CCA'].value_counts())\n",
    "\n",
    "print(f\"Total missing values in the column: {df['CCA'].isna().sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd64dcc6",
   "metadata": {},
   "source": [
    "As there are duplicates in the CCA values, we need to standardize on the values but converting them to upper case.\n",
    "\n",
    "Also, as there are missing values in the column, it will be set to 'NONE'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0753a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all values to uppercase\n",
    "df['CCA'] = df['CCA'].str.upper()\n",
    "Logger.debug('Converting to uppercase all values in CCA column.')\n",
    "\n",
    "# Filling the missing values with the 'NONE' category\n",
    "df['CCA'] = df['CCA'].fillna('NONE')\n",
    "Logger.debug('Filling all blank values in CCA to NONE.')\n",
    "\n",
    "# Display the breakdown again\n",
    "display(df['CCA'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a0c86",
   "metadata": {},
   "source": [
    "### Creating sleep duration column\n",
    "\n",
    "The 2 columns - **sleep_time** and **wake_time** - seem to be stgoring the times the students sleep and awake for school. in HH:MM format. These 2 columns will be converted into datetime formaats. Then, an arithmatic operation will be performed to calculate the sleep duration of the student. Then, it will be converted into minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 2 string columns to datetime objects\n",
    "df['sleep_time_dt'] = pd.to_datetime(df['sleep_time'], format='%H:%M')\n",
    "df['wake_time_dt'] = pd.to_datetime(df['wake_time'], format='%H:%M')\n",
    "Logger.debug('Converted sleep_time and wake_time columns to datetime formats.')\n",
    "\n",
    "# Calculate the duration, not forgetting to handle the overnight timings\n",
    "duration = np.where(\n",
    "    df['wake_time_dt'] < df['sleep_time_dt'],\n",
    "    # If wake time is \"before\" sleep time, add a day to wake time\n",
    "    df['wake_time_dt'] + pd.Timedelta(days=1) - df['sleep_time_dt'],\n",
    "    # Otherwise, it's a simple subtraction\n",
    "    df['wake_time_dt'] - df['sleep_time_dt']\n",
    ")\n",
    "df['sleep_duration'] = duration\n",
    "\n",
    "# Convert the duration (Timedelta) to total minutes\n",
    "df['sleep_minutes'] = (df['sleep_duration'].dt.total_seconds() / 60).astype(int)\n",
    "Logger.debug('Created sleep_duration feature in minutes.')\n",
    "\n",
    "# Display the column breakdown\n",
    "display(df['sleep_minutes'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the sleep minutes frequency breakdown\n",
    "df['sleep_minutes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865909c2",
   "metadata": {},
   "source": [
    "On the whole, more than 90% of students sleep at least 8 hours of sleep. in fact about 2.4% of the students do not get sufficient sleep, and they sleep at least 5 hours. Will need to investigate if sleep time impacts a student's final test result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beddfa8e",
   "metadata": {},
   "source": [
    "### Cleaning `tuition` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad921d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tuition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e36505f",
   "metadata": {},
   "source": [
    "There are inconsistencies in the values encoded into this column. There are 4 values for whether a sudent receives tuition or not. As such, we will standardize the encoding to only 2 values - 'Y' and 'N'. \n",
    "\n",
    "We will need to check if a model can differentiate if the student receiving higher marks received tuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b6421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create replacement mapping values\n",
    "tuition_replacement_code = {'Yes': 'Y', \n",
    "                            'No': 'N'\n",
    "                            }\n",
    "# Perform the replacement operationg\n",
    "df['tuition'] = df['tuition'].replace(tuition_replacement_code)\n",
    "Logger.debug('Standardized tuition column to 2 values.')\n",
    "\n",
    "# Verify that the replacement is successful\n",
    "df['tuition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca6236",
   "metadata": {},
   "source": [
    "### Filling up missing values in `attendance_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e282b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df['attendance_rate'].describe())\n",
    "\n",
    "print(f\"Total number of missing values: {df['attendance_rate'].isna().sum():,}\")\n",
    "# print(len(df['attendance_rate'].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a55664",
   "metadata": {},
   "source": [
    "As there are missing values in this column, about 778 observations, or 4.48%, we will use the median value of this column, which is at 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median value of the attendance_rate column\n",
    "attendance_rate_median = df['attendance_rate'].median()\n",
    "\n",
    "# Assign the missing values with the calculated median \n",
    "df['attendance_rate'] = df['attendance_rate'].fillna(attendance_rate_median)\n",
    "print('Missing values in attendance rate has been replaced with the median.')\n",
    "Logger.debug('Filled missing values in attendance_rate column witrh median.')\n",
    "\n",
    "# df['attendance_rate'].describe()\n",
    "\n",
    "# Checking if ther are any empty values in the CCQ column\n",
    "if df['attendance_rate'].isna().sum() == 0:\n",
    "    # No more missing values in the column\n",
    "    print('There are no more empty values.')\n",
    "    Logger.debug('There are no more missing values in the attendance_rate column.')\n",
    "else:\n",
    "    # There are still missing values\n",
    "    print('NOTE: There are still missing values in the column.')\n",
    "    print('This requires your attention')\n",
    "    Logger.debug('There are missing values in the attendance_rate column.')\n",
    "    Logger.debug(f\"Missing values in attendance_rate: {df['attendance_rate'].isna().sum()}\")\n",
    "    sys.exit(1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dee044",
   "metadata": {},
   "source": [
    "### Cleaning `final_test` column\n",
    "\n",
    "This column has missing values, and will also be replaced with the median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8cc053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the median value of the 'final_test' column\n",
    "final_test_median = df['final_test'].median()\n",
    "print(f\"The median value of the column {final_test_median}\")\n",
    "\n",
    "# Replacing the missing value with the median value\n",
    "df['final_test'].fillna(final_test_median, inplace = True)\n",
    "Logger.debug(f'Filling missing values in final_test column with median value {final_test_median}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec583355",
   "metadata": {},
   "source": [
    "The missing value in the `final_test` column has been replaced with the median value of the column, which is 68.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79bd125",
   "metadata": {},
   "source": [
    "### Checking `age` distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e962363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27c4a9e",
   "metadata": {},
   "source": [
    "From the frequency table above, there are several erroneous values in the `age` column. Thus, I would perform the following operations to rectify the problem:\n",
    "\n",
    "1. Take the absolute value of their ages.\n",
    "2. Create a replacement age map so that single digit values are converted into the teens (i.e., 14, 15, 16)\n",
    "3. Instead of leaving the single value of '14' as a standalone age value, I will change it to 15, as most students who sit for the 'O' level examinations are usually in their 15s and 16s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].abs()\n",
    "\n",
    "age_replacement_map = {4: 15,\n",
    "                       5: 15,\n",
    "                       6: 16\n",
    "                       }\n",
    "\n",
    "# Perform the replacement operationg\n",
    "df['age'] = df['age'].replace(age_replacement_map)\n",
    "Logger.debug('Corrected erroneous values in the age column.')\n",
    "\n",
    "# Verify that the replacement is successful\n",
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf217fc",
   "metadata": {},
   "source": [
    "### Checking if missing value still persists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07abe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.isnull().sum().sum())\n",
    "\n",
    "if df.isnull().sum().sum() == 0:\n",
    "    print('All missing values have been treated.')\n",
    "    Logger.debug('All missing values have been treated.')\n",
    "else:\n",
    "    print('There are still missing values in the dataset.')\n",
    "    Logger.debug('There are still missing values in the dataset.')\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the top 10 records of the post-cleaning\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c29b3fd",
   "metadata": {},
   "source": [
    "### Saving a clean copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_null_score = df[df['final_test'].isnull()]\n",
    "\n",
    "# df.dropna(inplace = True)\n",
    "\n",
    "# Creating a duplicate copy of the dataset post cleanup\n",
    "df_cleaned = df.copy(deep = True)\n",
    "\n",
    "df_cleaned.to_csv('./data/cleaned_data.csv')\n",
    "Logger.debug('Saved a clean copy to data folder.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185d4274",
   "metadata": {},
   "source": [
    "### Dropping non-essential columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8312cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing non-essential colukns\n",
    "columns_to_drop = ['index', 'student_id', 'sleep_time', 'wake_time', 'sleep_time_dt', 'wake_time_dt', 'sleep_duration']\n",
    "try:\n",
    "        df.drop(columns = columns_to_drop, \n",
    "                inplace = True)\n",
    "        Logger.debug(f'Dropped non-essential columns: {columns_to_drop}')\n",
    "except KeyError:\n",
    "        Logger.warning(f'Columns {columns_to_drop} not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af64ead",
   "metadata": {},
   "source": [
    "### Checking cleaned data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1892952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee77a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f811bad1",
   "metadata": {},
   "source": [
    "## Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logger.debug('Starting univariate analysis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f689a8e5",
   "metadata": {},
   "source": [
    "### Pie Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad47b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of columns\n",
    "columns_to_plot = [\n",
    "    'number_of_siblings', 'direct_admission', 'learning_style', \n",
    "    'gender', 'mode_of_transport', 'bag_color'\n",
    "]\n",
    "\n",
    "# Create a figure and a set of subplots, a 2x3 grid of pie charts\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(20, 12))\n",
    "fig.suptitle('Distribution of Categorical Features', fontsize=20)\n",
    "\n",
    "# Flatten the axes array to make it easy to loop over\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through columns and plot on each subplot\n",
    "for i, column in enumerate(columns_to_plot):\n",
    "    value_counts = df[column].value_counts()\n",
    "    ax = axes[i] # Select the subplot\n",
    "    \n",
    "    ax.pie(\n",
    "        value_counts, \n",
    "        labels=value_counts.index, \n",
    "        autopct='%1.1f%%', \n",
    "        startangle=90,\n",
    "        # Add some styling for a cleaner look\n",
    "        wedgeprops={'edgecolor': 'white'},\n",
    "        textprops={'fontsize': 18} \n",
    "    )\n",
    "    ax.set_title(f'{column.replace(\"_\", \" \").title()}', fontsize = 20)\n",
    "\n",
    "# If you have an odd number of plots, you might want to hide the last empty one\n",
    "# for i in range(len(columns_to_plot), len(axes)):\n",
    "#     fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make room for the suptitle\n",
    "plt.savefig(PLOT_PATH + \"pie_charts_6.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ea909",
   "metadata": {},
   "source": [
    "#### Analysis notes\n",
    "\n",
    "- **Number of siblings**: 42.2% of the observations in the cleaned dataset haws 1 other siblings, followed by 34.6% has no other siblings, while 23.3% has 2 siblings. It is possible that having siblings may lead to a higher test scores.\n",
    "- **Direct admission**: Nearly 3/4, or exactly 70.5% of the students did not get admitted directly.\n",
    "- **Learning style**: 57.4% of students learn through auditory methods, which means they acquire retain knowledge better listening to lectures and podcasts/videos. We would need to check students who learn through auditory or visual learning style.\n",
    "- **Gender**: Students are equally balanced between male and female.\n",
    "- **Mode of transport**: \n",
    "- **Bag color**: The color of the students' bags seems to be fairly distributed for all 6 colors. But does the choice of bag color affect a student's mathematics score?\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e87eba",
   "metadata": {},
   "source": [
    "### Histogram of `CCA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create the histogram using Matplotlib\n",
    "plt.figure(figsize=(10, 6)) # Set the figure size for better readability\n",
    "\n",
    "plt.hist(\n",
    "    df['CCA'], \n",
    "    bins=10,          # You can adjust the number of bins to see more or less detail\n",
    "    color='skyblue',  # Set the color of the bars\n",
    "    edgecolor='black' # Add black edges to bars for better separation\n",
    ")\n",
    "\n",
    "# 3. Add labels and a title for clarity\n",
    "plt.title('Distribution of CCA Participation', fontsize=16)\n",
    "plt.xlabel('CCA Participation', fontsize=12)\n",
    "plt.ylabel('Frequency (Number of Students)', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.75) # Add a grid for the y-axis\n",
    "\n",
    "# SDave the plot\n",
    "plt.savefig(PLOT_PATH + \"bar_chart_CCA.png\")\n",
    "\n",
    "# 4. Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16305a0b",
   "metadata": {},
   "source": [
    "#### Analysis notes\n",
    "\n",
    "The initial dataset has about 25% of observationds having missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bacf427",
   "metadata": {},
   "source": [
    "### Histogram of `final_test'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62a1f553",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# --- Plotting the histogram using pandas/matplotlib ---\n",
    "\n",
    "plt.figure(figsize=(10, 6)) # Adjust the figure size\n",
    "\n",
    "# Use the pandas .hist() method\n",
    "df['final_test'].hist(bins=10) ##, grid=False, color='#86bf91')\n",
    "\n",
    "# Add titles and labels for clarity\n",
    "plt.title(\"Distribution of Final Test Scores\", fontsize=16)\n",
    "plt.xlabel(\"Final Test Score\", fontsize=12)\n",
    "plt.ylabel(\"Number of Students\", fontsize=12)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba89051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a visually appealing style for the plot\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# Create a figure and axes for the plot. This allows for size adjustments.\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Generate the histogram using seaborn's histplot\n",
    "# 'kde=True' adds a smooth line to estimate the distribution's shape\n",
    "ax = sns.histplot(data=df, x='final_test', bins=15, kde=True)  ## color='skyblue')\n",
    "\n",
    "# --- 3. Customizing the Plot ---\n",
    "\n",
    "# Add a title and labels for clarity and professionalism\n",
    "ax.set_title('Distribution of Final Test Scores') ## , fontsize=18, pad=20)\n",
    "ax.set_xlabel('Final Test Score')  ##, fontsize=14)\n",
    "ax.set_ylabel('Number of Students (Frequency)') ##, fontsize=14)\n",
    "\n",
    "# You can even add a vertical line for the mean score\n",
    "mean_score = df['final_test'].mean()\n",
    "ax.axvline(mean_score, color='red', linestyle='--', linewidth=2, label=f'Mean Score: {mean_score:.2f}')\n",
    "ax.legend() # Display the label for the mean line\n",
    "\n",
    "plt.savefig(PLOT_PATH + 'histogram_CCA.png')\n",
    "\n",
    "# Display the final plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfd839d",
   "metadata": {},
   "source": [
    "### Boxplot of `attendance_rate` and `final_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for a cleaner look\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Create a figure and a set of subplots (1 row, 2 columns)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "# Plot for Attendance Rate\n",
    "sns.boxplot(ax=axes[0], y=df['attendance_rate'], color='skyblue')\n",
    "axes[0].set_title('Distribution of Attendance Rate') ##, fontsize=14)\n",
    "axes[0].set_ylabel('Rate (%)')\n",
    "axes[0].set_xlabel('') # Hide x-axis label as it's not needed\n",
    "\n",
    "# Plot for Final Test\n",
    "sns.boxplot(ax=axes[1], y=df['final_test'], color='lightgreen')\n",
    "axes[1].set_title('Distribution of Final Test Scores')  ##, fontsize=14)\n",
    "axes[1].set_ylabel('Score (%)')\n",
    "axes[1].set_xlabel('') # Hide x-axis label\n",
    "\n",
    "# Add a main title for the entire figure\n",
    "plt.suptitle('Boxplot of Attendance Rate and Final Test Score', fontsize=16, y=1.02)\n",
    "\n",
    "# Adjust layout to prevent titles from overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(PLOT_PATH + 'boxplot.png')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c341a97f",
   "metadata": {},
   "source": [
    "From the above charts, there are a number of outliers in the attendance rate, but not for the marks for the Mathematics test. I will investigate on the quantum of students whose attendance is lower than the lower bound of the boxplot and whether there is any correlation with their final marks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89616810",
   "metadata": {},
   "source": [
    "#### Investigate the `attendance_rate` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83098454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column under investigation\n",
    "col = 'attendance_rate'\n",
    "\n",
    "# print(df[col].quantile(0.25))\n",
    "# print(df[col].quantile(0.75))\n",
    "\n",
    "# Calculate the Interquartile Range\n",
    "iqr = df[col].quantile(0.75) - df[col].quantile(0.25)\n",
    "# print(iqr)\n",
    "# Calculate the lower bound of the distribution\n",
    "lower_bound = df[col].quantile(0.25) - (1.5 * iqr)\n",
    "# print(lower_bound)\n",
    "\n",
    "print(f\"Total number of students whose attendance rate is below the lower bound: {len(df[df[col] < lower_bound]):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca29a49",
   "metadata": {},
   "source": [
    "### Barchart of `age` column"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9698663f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Set a visually appealing style for the plot\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# Create a figure and axes for the plot. This allows for size adjustments.\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Generate the histogram using seaborn's histplot\n",
    "# 'kde=True' adds a smooth line to estimate the distribution's shape\n",
    "ax = sns.histplot(data=df, x='age', bins=1, kde=True)  ## color='skyblue')\n",
    "\n",
    "# --- 3. Customizing the Plot ---\n",
    "\n",
    "# Add a title and labels for clarity and professionalism\n",
    "ax.set_title('Distribution of Students\\' Age') ## , fontsize=18, pad=20)\n",
    "ax.set_xlabel('Age')  ##, fontsize=14)\n",
    "ax.set_ylabel('Number of Students (Frequency)') ##, fontsize=14)\n",
    "\n",
    "# You can even add a vertical line for the mean score\n",
    "mean_score = df['age'].mean()\n",
    "ax.axvline(mean_score, color='red', linestyle='--', linewidth=2, label=f'Mean Score: {mean_score:.2f}')\n",
    "ax.legend() # Display the label for the mean line\n",
    "\n",
    "plt.savefig(PLOT_PATH + 'histogram_age.png')\n",
    "\n",
    "# Display the final plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea9115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each unique age using value_counts() to create a Series\n",
    "age_counts = df['age'].value_counts().sort_index()\n",
    "\n",
    "# --- 2. Create the Bar Chart from the counts ---\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use sns.barplot on the counted data\n",
    "ax = sns.barplot(x=age_counts.index, y=age_counts.values, palette='viridis')\n",
    "\n",
    "# --- Add Titles and Labels ---\n",
    "ax.set_title('Bar Chart of Age Counts')  ##, fontsize=16)\n",
    "ax.set_xlabel('Age')  ##, fontsize=12)\n",
    "ax.set_ylabel('Frequency (Count)')  ##, fontsize=12)\n",
    "\n",
    "# Improve readability of x-axis labels if there are many ages\n",
    "plt.xticks(rotation=45)  ##, ha='right')\n",
    "plt.tight_layout() # Adjust layout to make room for rotated labels\n",
    "\n",
    "plt.savefig(PLOT_PATH + 'barchart')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ac69f",
   "metadata": {},
   "source": [
    "The students age are equally balanced for 15 and 16 years. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5832fb1d",
   "metadata": {},
   "source": [
    "### Breakdown of Students' Age by Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e43fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a cross tabular data for age and gender columns\n",
    "age_gender_crosstab = pd.crosstab(index = df['age'],\n",
    "                                  columns = df['gender'])\n",
    "\n",
    "print(age_gender_crosstab)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "436708e1",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # --- Use the same sample data and age grouping as above ---\n",
    "# np.random.seed(101)\n",
    "# size = 500\n",
    "# ages = np.random.normal(loc=40, scale=15, size=size).astype(int)\n",
    "# genders = np.random.choice(['Male', 'Female'], size=size, p=[0.52, 0.48])\n",
    "# df = pd.DataFrame({'age': ages, 'gender': genders})\n",
    "# df = df[(df['age'] >= 18) & (df['age'] <= 80)].reset_index(drop=True)\n",
    "# bins = [18, 29, 39, 49, 59, 69, float('inf')]\n",
    "# labels = ['18-29', '30-39', '40-49', '50-59', '60-69', '70+']\n",
    "# df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# # --- 1. Reshape the data using crosstab ---\n",
    "# # pd.crosstab creates a \"contingency table\" perfect for stacked charts\n",
    "# cross_tab = pd.crosstab(index=df['age_group'], columns=df['gender'])\n",
    "\n",
    "# --- 2. Create the Stacked Bar Chart ---\n",
    "ax = age_gender_crosstab.plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    figsize=(14, 8),\n",
    "    color=['lightcoral', 'royalblue'] # Match colors to gender\n",
    ")\n",
    "\n",
    "# --- 3. Add Titles and Labels ---\n",
    "ax.set_title('Student Count by Age Group and Gender (Stacked)', fontsize=18, pad=15)\n",
    "ax.set_xlabel('Age Group', fontsize=14)\n",
    "ax.set_ylabel('Total Count', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right') # Rotate labels for better fit\n",
    "plt.legend(title='Gender', fontsize='large', title_fontsize='x-large')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(PLOT_PATH_'barchart_age_gender.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d7f2a",
   "metadata": {},
   "source": [
    "### Analysis of `hours_per_week`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f1e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hours_per_week'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f03a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a visually appealing style for the plot\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# Create a figure and axes for the plot. This allows for size adjustments.\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Generate the histogram using seaborn's histplot\n",
    "# 'kde=True' adds a smooth line to estimate the distribution's shape\n",
    "ax = sns.histplot(data=df, x='hours_per_week', bins=5, kde=True)  ## color='skyblue')\n",
    "\n",
    "# --- 3. Customizing the Plot ---\n",
    "\n",
    "# Add a title and labels for clarity and professionalism\n",
    "ax.set_title('Distribution of Number of Hours Put in to Study') ## , fontsize=18, pad=20)\n",
    "ax.set_xlabel('Number of Hours')  ##, fontsize=14)\n",
    "ax.set_ylabel('Number of Students (Frequency)') ##, fontsize=14)\n",
    "\n",
    "# You can even add a vertical line for the mean score\n",
    "mean_score = df['hours_per_week'].mean()\n",
    "ax.axvline(mean_score, color='red', linestyle='--', linewidth=2, label=f'Mean Score: {mean_score:.2f}')\n",
    "ax.legend() # Display the label for the mean line\n",
    "\n",
    "plt.savefig(PLOT_PATH + 'histogram_hrs_per_week.png')\n",
    "\n",
    "# Display the final plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429387bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ac66c5d",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47601f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logger.debug('Starting Bivariate Analysis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4825892d",
   "metadata": {},
   "source": [
    "### Comparing Sleep against Final Results Attained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867df929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create and plot the dot plot (scatter plot) ---\n",
    "plt.figure(figsize=(10, 6)) # Set the figure size\n",
    "\n",
    "# Create the scatter plot\n",
    "sns.scatterplot(\n",
    "    data=df, \n",
    "    x='sleep_minutes', \n",
    "    y='final_test',\n",
    "    alpha=0.7, # Make points slightly transparent to see overlaps\n",
    "    edgecolor='k', # Add a black edge to dots for better visibility\n",
    "    s=80 # Set the size of the dots\n",
    ")\n",
    "\n",
    "# Add enhancements for clarity\n",
    "plt.title('Final Test Score vs. Sleep Minutes', fontsize=16)\n",
    "plt.xlabel('Sleep per Night (Minutes)', fontsize=12)\n",
    "plt.ylabel('Final Test Score', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb27e2",
   "metadata": {},
   "source": [
    "### Comparing Attendance Rate against Final Results Attained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5acc94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create and plot the dot plot (scatter plot) ---\n",
    "plt.figure(figsize=(10, 6)) # Set the figure size\n",
    "\n",
    "# Create the scatter plot\n",
    "sns.scatterplot(\n",
    "    data=df, \n",
    "    x='final_test', \n",
    "    y='attendance_rate',\n",
    "    alpha=0.7, # Make points slightly transparent to see overlaps\n",
    "    edgecolor='k', # Add a black edge to dots for better visibility\n",
    "    s=80 # Set the size of the dots\n",
    ")\n",
    "\n",
    "# Add enhancements for clarity\n",
    "plt.title('Final Test Score vs. Sleep Minutes', fontsize=16)\n",
    "plt.xlabel('Sleep per Night (Minutes)', fontsize=12)\n",
    "plt.ylabel('Final Test Score', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd970a5e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3764aa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create and plot the dot plot (scatter plot) ---\n",
    "plt.figure(figsize=(10, 6)) # Set the figure size\n",
    "\n",
    "# Create the scatter plot\n",
    "sns.scatterplot(\n",
    "    data=df, \n",
    "    x='sleep_minutes', \n",
    "    y='attendance_rate',\n",
    "    alpha=0.7, # Make points slightly transparent to see overlaps\n",
    "    edgecolor='k', # Add a black edge to dots for better visibility\n",
    "    s=80 # Set the size of the dots\n",
    ")\n",
    "\n",
    "# Add enhancements for clarity\n",
    "plt.title('Final Test Score vs. Sleep Minutes', fontsize=16)\n",
    "plt.xlabel('Sleep per Night (Minutes)', fontsize=12)\n",
    "plt.ylabel('Final Test Score', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd3ef3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cd81f24",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e2c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logger.info('Performing Correlation Analysis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c874136",
   "metadata": {},
   "source": [
    "### Creating a correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbc3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix\n",
    "corr_matrix = df[['hours_per_week', 'attendance_rate', 'sleep_minutes', 'final_test']].corr()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d85ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix\n",
    "corr_matrix2 = df[['attendance_rate', 'sleep_minutes']].corr()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(corr_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee40bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the plot style\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Plot the correlation map (heatmap)\n",
    "plt.figure(figsize=(10, 8)) # Set the size of the figure\n",
    "sns.heatmap(\n",
    "    corr_matrix, \n",
    "    annot=True,          # Annotate the values in the cells\n",
    "    cmap='coolwarm',     # Choose a color map\n",
    "    fmt=\".2f\",           # Format the annotations to two decimal places\n",
    "    linewidths=.5        # Add lines between cells\n",
    ")\n",
    "\n",
    "plt.title('Correlation Map of Student Data', fontsize=16)\n",
    "\n",
    "plt.savefig(PLOT_PATH + 'heatmap_test_sleep_attendance_study_hrs.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebfa414",
   "metadata": {},
   "source": [
    "From the heatmap above, the features `'sleep_minutes'` and `'attendance_rate'` are highly correlated at 0.87. As such, I will drop the column `'sleep_minutes'` from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9a93e3",
   "metadata": {},
   "source": [
    "#### Dropping the feature `sleep_minutes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3318ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['sleep_minutes'], inplace = True)\n",
    "Logger.info('Dropping sleep_minutes column as it highly correlates with attendance_rate column.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922e6dd0",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f78b0",
   "metadata": {},
   "source": [
    "### Feature/Target Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9041b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the feature from the target\n",
    "X = df.drop(columns = ['final_test'])\n",
    "y = df['final_test']\n",
    "Logger.debug('Performed Feature/Target separation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4aac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d1e645",
   "metadata": {},
   "source": [
    "### Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c90f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training (80%) and test-validation (20%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Split the test-validation set (20%) into validation (10%) and test (10%) sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "Logger.debug('Performed train/validation/test split.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df987d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shapes of the splits to verify\n",
    "print('Training set shape:\\t', X_train.shape, y_train.shape)\n",
    "Logger.debug(f'Training set shape: {X_train.shape} by {y_train.shape}')\n",
    "\n",
    "print('Validation set shape:\\t', X_val.shape, y_val.shape)\n",
    "Logger.debug(f'Validation set shape: {X_train.shape} by {y_val.shape}')\n",
    "\n",
    "print('Test set shape:\\t\\t', X_test.shape, y_test.shape)\n",
    "Logger.debug(f'Test set shape: {X_test.shape} by {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a28d01",
   "metadata": {},
   "source": [
    "## Build a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577371d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logger.debug('Building machine learning pipeline.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382e29d4",
   "metadata": {},
   "source": [
    "### Implementing Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9af1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define numerical features to be standardized\n",
    "numerical_features = ['n_male', 'n_female', 'hours_per_week', 'attendance_rate']\n",
    "\n",
    "# Create a numerical transformer pipeline\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "Logger.debug(f'Preparing numerical_transformer, standardizing numerical features: {numerical_features}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee81544",
   "metadata": {},
   "source": [
    "### Implementing Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Define nomial features to be one-hot encoded\n",
    "nominal_features = ['direct_admission', 'CCA', 'learning_style', 'tuition', 'gender', 'bag_color']\n",
    "\n",
    "# Define passthrough features that will not be transformed\n",
    "passthrough_features = ['age']\n",
    "\n",
    "# Create a nominal transformer pipeline\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "Logger.debug(f'Preparing nominal_transformer, performing one-hot encoding on nominal features: {nominal_features}.')\n",
    "Logger.debug(f'Preparing passthrough feature: {passthrough_features}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c6c617",
   "metadata": {},
   "source": [
    "### Combine Feature Scaling and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95406721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Combine transformers into a single ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('nom', nominal_transformer, nominal_features),\n",
    "        ('pass', 'passthrough', passthrough_features) # Pass through the storey_range feature without transformation\n",
    "    ],\n",
    "#     remainder='passthrough',\n",
    "    n_jobs=-1\n",
    "    )\n",
    "Logger.debug('Preparing ColumnTransformer - preprocessor with the numerical, nominal and passthrough transformers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe4bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84430581",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c40b7",
   "metadata": {},
   "source": [
    "### Implementring Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed5eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logger.debug('Implementing Multivariate Linear Regression.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db434c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create the pipeline with a linear regression model\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "Logger.debug('Building a Linear Regression Model with the preprocessor ColumnTransformer object.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73aa469",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a55614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the training data\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "Logger.debug('Fitting the training dataset to the Multivariate Linear Regression model - lr_pipeline.')\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = lr_pipeline.predict(X_val)\n",
    "Logger.debug('Predicting on the validation set - y_val_pred.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ff1152",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a945d4",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd77c4",
   "metadata": {},
   "source": [
    "### Implementing Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa01e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error, r2_score\n",
    "\n",
    "# Calculate regression metrics for validation set\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "val_rmse = root_mean_squared_error(y_val, y_val_pred)  # RMSE is the square root of MSE\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Display the metrics\n",
    "Logger.debug('Model metrics of Multivariate Linear Regression.')\n",
    "print(f\"Validation MAE: {val_mae:,.4f}\")\n",
    "Logger.debug(f\"Validation MAE: {val_mae:,.4f}\")\n",
    "print(f\"Validation MSE: {val_mse:,.4f}\")\n",
    "Logger.debug(f\"Validation MSE: {val_mse:,.4f}\")\n",
    "print(f\"Validation RMSE: {val_rmse:,.4f}\")\n",
    "Logger.debug(f\"Validation RMSE: {val_rmse:,.4f}\")\n",
    "print(f\"Validation R²: {val_r2:,.4f}\")\n",
    "Logger.debug(f\"Validation R²: {val_r2:,.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d77042e",
   "metadata": {},
   "source": [
    "### Implementring Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logger.debug('Initating Ridge Regression Model.')\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Fit Ridge Regression with lambda (alpha in scikit-learn)\n",
    "ridge_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge(alpha=1))\n",
    "])\n",
    "Logger.debug('Building a Ridge Regression Model with the preprocessor ColumnTransformer object.')\n",
    "\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "\n",
    "Logger.debug('Fitting the training dataset to the Multivariate Linear Regression model - lr_pipeline.')\n",
    "\n",
    "# Predict on the validation set with Ridge Regression\n",
    "y_val_pred_ridge = ridge_pipeline.predict(X_val)\n",
    "Logger.debug('Predicting on the validation set - y_val_pred_ridge.')\n",
    "\n",
    "# Calculate regression metrics for validation set with Ridge Regression\n",
    "val_mae_ridge = mean_absolute_error(y_val, y_val_pred_ridge)\n",
    "val_mse_ridge = mean_squared_error(y_val, y_val_pred_ridge)\n",
    "val_rmse_ridge = root_mean_squared_error(y_val, y_val_pred_ridge)  # RMSE is the square root of MSE\n",
    "val_r2_ridge = r2_score(y_val, y_val_pred_ridge)\n",
    "\n",
    "# Display the metrics for Ridge Regression\n",
    "print(\"Ridge Regression Metrics:\")\n",
    "Logger.debug('Model metrics of Ridge Regression.')\n",
    "print(f\"Ridge Validation MAE: {val_mae_ridge:,.4f}\")\n",
    "Logger.debug(f\"Validation MAE: {val_mae_ridge:,.4f}\")\n",
    "print(f\"Ridge Validation MSE: {val_mse_ridge:,.4f}\")\n",
    "Logger.debug(f\"Validation MSE: {val_mse_ridge:,.4f}\")\n",
    "print(f\"Ridge Validation RMSE: {val_rmse_ridge:,.4f}\")\n",
    "Logger.debug(f\"Validation RMSE: {val_rmse_ridge:,.4f}\")\n",
    "print(f\"Ridge Validation R²: {val_r2_ridge:,.4f}\")\n",
    "Logger.debug(f\"Validation R²: {val_r2_ridge:,.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cb25d2",
   "metadata": {},
   "source": [
    "#### Comparing Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5116f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the coefficients of the linear regression model\n",
    "lr_coefs = lr_pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "# Extract the coefficients of the ridge regression model\n",
    "ridge_coefs = ridge_pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "# Assuming feature_names contains the names of the features after preprocessing\n",
    "feature_names = (\n",
    "    numerical_features +\n",
    "    list(ridge_pipeline.named_steps['preprocessor'].transformers_[1][1].named_steps['onehot'].get_feature_names_out(nominal_features)) +\n",
    "    # ordinal_features +\n",
    "    passthrough_features\n",
    ")\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Linear Regression': lr_coefs,\n",
    "    'Ridge Regression': ridge_coefs\n",
    "})\n",
    "\n",
    "# Melt the DataFrame to long format for seaborn\n",
    "coef_df = coef_df.melt(id_vars='Feature', var_name='Model', value_name='Coefficient')\n",
    "\n",
    "# Plotting the coefficients with seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=coef_df, x='Feature', y='Coefficient', hue='Model', palette=['darkblue', 'lightgreen'])\n",
    "\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Coefficient Magnitude')\n",
    "plt.title('Bar Plot of Linear Regression and Ridge Regression Coefficients')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True, axis='y')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(PLOT_PATH + 'linear_ridge_regression_coefficients.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4875ff5",
   "metadata": {},
   "source": [
    "##### Analysis of the comparison of the Linear Regression and a regularized Ridge Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84147d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f9a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "'number_of_siblings', 'direct_admission', 'CCA', 'learning_style', 'gender', 'tuition', 'n_male', 'n_female', 'age', 'hours_per_week', 'attendance_rate', 'mode_of_transport', 'bag_color'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb09a3c",
   "metadata": {},
   "source": [
    "### Implementing Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406481a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Fit Lasso Regression with default alpha\n",
    "lasso_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Lasso(alpha=1))\n",
    "])\n",
    "lasso_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set with Lasso Regression\n",
    "y_val_pred_lasso = lasso_pipeline.predict(X_val)\n",
    "\n",
    "# Calculate regression metrics for validation set with Lasso Regression\n",
    "val_mae_lasso = mean_absolute_error(y_val, y_val_pred_lasso)\n",
    "val_mse_lasso = mean_squared_error(y_val, y_val_pred_lasso)\n",
    "val_rmse_lasso = root_mean_squared_error(y_val, y_val_pred_lasso)  # RMSE is the square root of MSE\n",
    "val_r2_lasso = r2_score(y_val, y_val_pred_lasso)\n",
    "\n",
    "# Display the metrics for Lasso Regression\n",
    "print(\"Lasso Regression Metrics:\")\n",
    "print(f\"Lasso Validation MAE: {val_mae_lasso:,.4f}\")\n",
    "print(f\"Lasso Validation MSE: {val_mse_lasso:,.4f}\")\n",
    "print(f\"Lasso Validation RMSE: {val_rmse_lasso:,.4f}\")\n",
    "print(f\"Lasso Validation R²: {val_r2_lasso:,.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd9789b",
   "metadata": {},
   "source": [
    "#### Comparing Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2057bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the coefficients of the linear and lasso regression models\n",
    "lr_coefs = lr_pipeline.named_steps['regressor'].coef_\n",
    "lasso_coefs = lasso_pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "# Extract feature names after preprocessing\n",
    "feature_names = (\n",
    "    numerical_features +\n",
    "    list(preprocessor.transformers_[1][1].named_steps['onehot'].get_feature_names_out(nominal_features)) +\n",
    "    # ordinal_features +\n",
    "    passthrough_features\n",
    ")\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    # 'Linear Regression': lr_coefs,\n",
    "    'Lasso Regression': lasso_coefs\n",
    "})\n",
    "\n",
    "# Melt the DataFrame to long format for seaborn\n",
    "coef_df = coef_df.melt(id_vars='Feature', var_name='Model', value_name='Coefficient')\n",
    "\n",
    "# Plotting the coefficients with seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=coef_df, x='Feature', y='Coefficient', hue='Model', palette=['darkblue', 'salmon'])\n",
    "\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Coefficient Magnitude')\n",
    "plt.title('Bar Plot of Linear Regression and Lasso Regression Coefficients')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True, axis='y')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(PLOT_PATH + 'linear_lasso_regression_coefficients.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135562aa",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "From the above graphs, 4 features are showing to have strong impact on the target are, by order of absolute coefficient values:\n",
    "- CCA_NONE\n",
    "- n_female\n",
    "- n_male\n",
    "- attendance_rate\n",
    "\n",
    "The following 3 columns have some lower impact on the targer.\n",
    "- learning_stle_Auditory\n",
    "- tuition_N\n",
    "- hours_per_week\n",
    "\n",
    "The other columns have zero impact and will be omitted from the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d04c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd01663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(lr_coefs)\n",
    "# display(ridge_coefs)\n",
    "# display(lasso_coefs)\n",
    "consol_df_coefs = pd.DataFrame({\n",
    "    'Feature_name': feature_names,\n",
    "    'Linear_Regression': lr_coefs,\n",
    "    'Ridge_Regression': ridge_coefs,\n",
    "    'Lasso_Regression': lasso_coefs\n",
    "})\n",
    "display(consol_df_coefs)\n",
    "consol_df_coefs.to_csv('./data/consol_df_coefs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531d7298",
   "metadata": {},
   "outputs": [],
   "source": [
    "consol_df_coefs['Lasso_Regression'] = np.abs(consol_df_coefs['Lasso_Regression'])\n",
    "consol_df_coefs = consol_df_coefs.sort_values(by='Lasso_Regression', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# --- 4. Select Non-Zero Features ---\n",
    "\n",
    "# A feature is \"selected\" if its coefficient is not zero (or very close to zero due to machine precision)\n",
    "selected_features_df = consol_df_coefs[consol_df_coefs['Lasso_Regression'] != 0].copy()\n",
    "display(selected_features_df)\n",
    "# Get a list of the names of the selected features\n",
    "final_selected_features = selected_features_df['Feature_name'].tolist()\n",
    "display(final_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coefs_df = pd.DataFrame({\n",
    "    'Feature_name': feature_names,\n",
    "    'Lasso_Regression': lasso_coefs\n",
    "})\n",
    "lasso_coefs_df['Lasso_Regression'] = lasso_coefs_df['Lasso_Regression'].abs()\n",
    "# features = lasso_coefs_df[lasso_coefs_df['Lasso_Regression'] > 0]\n",
    "# display(lasso_coefs_df[lasso_coefs_df['Lasso_Regression'] > 0])\n",
    "display(lasso_coefs_df)\n",
    "# display(features)\n",
    "# 2. Filter for coefficients greater than 0\n",
    "# positive_coefs = lasso_coefs_df[lasso_coefs_df['Lasso_Regression'] > 0]\n",
    "# display(positive_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a473d6f0",
   "metadata": {},
   "source": [
    "The "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479115d",
   "metadata": {},
   "source": [
    "### Implementing GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a48bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__alpha': [0.1, 1, 10, 100, 1000],\n",
    "    'regressor__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Create the pipeline with a ridge regression model\n",
    "ridge_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge())\n",
    "])\n",
    "\n",
    "# Create the pipeline with a lasso regression model\n",
    "lasso_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Lasso())\n",
    "])\n",
    "\n",
    "# Perform grid search with cross-validation for Ridge regression\n",
    "ridge_grid_search = GridSearchCV(ridge_pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "ridge_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Perform grid search with cross-validation for Lasso regression\n",
    "lasso_grid_search = GridSearchCV(lasso_pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "lasso_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fcf0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters found by grid search for Ridge regression\n",
    "print(\"Best Ridge parameters:\", ridge_grid_search.best_params_)\n",
    "\n",
    "# Print the best parameters found by grid search for Lasso regression\n",
    "print(\"Best Lasso parameters:\", lasso_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best Ridge model on the validation set\n",
    "best_ridge_model = ridge_grid_search.best_estimator_\n",
    "y_val_pred_ridge = best_ridge_model.predict(X_val)\n",
    "\n",
    "# Calculate regression metrics for validation set for Ridge\n",
    "val_mae_ridge = mean_absolute_error(y_val, y_val_pred_ridge)\n",
    "val_mse_ridge = mean_squared_error(y_val, y_val_pred_ridge)\n",
    "val_rmse_ridge = root_mean_squared_error(y_val, y_val_pred_ridge)  # RMSE is the square root of MSE\n",
    "val_r2_ridge = r2_score(y_val, y_val_pred_ridge)\n",
    "\n",
    "print(\"Best Ridge Regression Metrics:\")\n",
    "print(f\"Ridge Validation MAE: {val_mae_ridge:.4f}\")\n",
    "print(f\"Ridge Validation MSE: {val_mse_ridge:.4f}\")\n",
    "print(f\"Ridge Validation RMSE: {val_rmse_ridge:.4f}\")\n",
    "print(f\"Ridge Validation R²: {val_r2_ridge:.4f}\")\n",
    "print()\n",
    "\n",
    "# Evaluate the best Lasso model on the validation set\n",
    "best_lasso_model = lasso_grid_search.best_estimator_\n",
    "y_val_pred_lasso = best_lasso_model.predict(X_val)\n",
    "\n",
    "# Calculate regression metrics for validation set for Lasso\n",
    "val_mae_lasso = mean_absolute_error(y_val, y_val_pred_lasso)\n",
    "val_mse_lasso = mean_squared_error(y_val, y_val_pred_lasso)\n",
    "val_rmse_lasso = root_mean_squared_error(y_val, y_val_pred_lasso)  # RMSE is the square root of MSE\n",
    "val_r2_lasso = r2_score(y_val, y_val_pred_lasso)\n",
    "\n",
    "print(\"Best Lasso Regression Metrics:\")\n",
    "print(f\"Lasso Validation MAE: {val_mae_lasso:.4f}\")\n",
    "print(f\"Lasso Validation MSE: {val_mse_lasso:.4f}\")\n",
    "print(f\"Lasso Validation RMSE: {val_rmse_lasso:.4f}\")\n",
    "print(f\"Lasso Validation R²: {val_r2_lasso:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c3a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters found by grid search for Ridge regression\n",
    "print(\"Best Ridge parameters:\", ridge_grid_search.best_params_)\n",
    "\n",
    "# Print the best parameters found by grid search for Lasso regression\n",
    "print(\"Best Lasso parameters:\", lasso_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc32c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best Ridge model on the validation set\n",
    "best_ridge_model = ridge_grid_search.best_estimator_\n",
    "print(best_ridge_model)\n",
    "y_val_pred_ridge = best_ridge_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537644de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate regression metrics for validation set for Ridge\n",
    "val_mae_ridge = mean_absolute_error(y_val, y_val_pred_ridge)\n",
    "val_mse_ridge = mean_squared_error(y_val, y_val_pred_ridge)\n",
    "val_rmse_ridge = root_mean_squared_error(y_val, y_val_pred_ridge)  # RMSE is the square root of MSE\n",
    "val_r2_ridge = r2_score(y_val, y_val_pred_ridge)\n",
    "\n",
    "print(\"Best Ridge Regression Metrics:\")\n",
    "print(f\"Ridge Validation MAE: {val_mae_ridge:,.4f}\")\n",
    "print(f\"Ridge Validation MSE: {val_mse_ridge:,.4f}\")\n",
    "print(f\"Ridge Validation RMSE: {val_rmse_ridge:,.4f}\")\n",
    "print(f\"Ridge Validation R²: {val_r2_ridge:,.4f}\")\n",
    "print()\n",
    "\n",
    "# Evaluate the best Lasso model on the validation set\n",
    "best_lasso_model = lasso_grid_search.best_estimator_\n",
    "y_val_pred_lasso = best_lasso_model.predict(X_val)\n",
    "\n",
    "# Calculate regression metrics for validation set for Lasso\n",
    "val_mae_lasso = mean_absolute_error(y_val, y_val_pred_lasso)\n",
    "val_mse_lasso = mean_squared_error(y_val, y_val_pred_lasso)\n",
    "val_rmse_lasso = root_mean_squared_error(y_val, y_val_pred_lasso)  # RMSE is the square root of MSE\n",
    "val_r2_lasso = r2_score(y_val, y_val_pred_lasso)\n",
    "\n",
    "print(\"Best Lasso Regression Metrics:\")\n",
    "print(f\"Lasso Validation MAE: {val_mae_lasso:,.4f}\")\n",
    "print(f\"Lasso Validation MSE: {val_mse_lasso:,.4f}\")\n",
    "print(f\"Lasso Validation RMSE: {val_rmse_lasso:,.4f}\")\n",
    "print(f\"Lasso Validation R²: {val_r2_lasso:,.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cda1185",
   "metadata": {},
   "source": [
    "### Implementing RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88071225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model from Ridge regression (Grid Search)\n",
    "best_ridge_model = ridge_grid_search.best_estimator_\n",
    "\n",
    "print(best_lasso_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2114ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set with Ridge Regression\n",
    "y_test_pred_ridge = best_ridge_model.predict(X_test)\n",
    "\n",
    "# Calculate regression metrics for the test set for Ridge\n",
    "test_mae_ridge = mean_absolute_error(y_test, y_test_pred_ridge)\n",
    "test_mse_ridge = mean_squared_error(y_test, y_test_pred_ridge)\n",
    "test_rmse_ridge = root_mean_squared_error(y_test, y_test_pred_ridge)\n",
    "test_r2_ridge = r2_score(y_test, y_test_pred_ridge)\n",
    "\n",
    "print(\"Best Ridge Regression Model, Final Test Metrics:\")\n",
    "print(f\"Final Test MAE: {test_mae_ridge:,.4f}\")\n",
    "print(f\"Final Test MSE: {test_mse_ridge:,.4f}\")\n",
    "print(f\"Final Test RMSE: {test_rmse_ridge:,.4f}\")\n",
    "print(f\"Final Test R²: {test_r2_ridge:,.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d54faa2",
   "metadata": {},
   "source": [
    "***End of Notebook***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiap21_tech_asst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
